---
title: "GLMM Maternal Mortality Federally- Summer 2025"
subtitle: "This is a Report Template"
author: "Carolyn Herrera & Catherine Funte (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction


Generalized Linear Mixed Models (GLMMs) are a flexible class of statistical models that combine the features of two powerful tools: Generalized Linear Models (GLMs) and Mixed-Effects Models[@agresti2015foundations]. Like GLMs, GLMMs can model non-normal outcome variables, such as binary, count, or proportion data. However, they go a step further by incorporating random effects, which account for variation due to grouping or clustering in the data, correlated observations, and overdispersion. The GLMM method can work with complex data structures such as temporal correlation, spatial correlation , nested data, heterogeneity of variance, and repeated measurement[@zuur2009mixed].  

In practical terms, GLMMs are especially useful when data points are not independent, such as when students are nested within schools, patients are treated within hospitals, or repeated measures are taken from the same subject over time. For example, Thall wrote that issues with longitudinal clinical trial basic count data from repeated measures taken from the same subject over time will have problems detecting comparable between subject outcomes because it can be difficult to determine if outcomes are time dependent or due to treatment groups, thus a general linear mixed model method may be utilized to represent dependence upon each patient, incorporate covariate data, create time as a function, account for variability between patients,and  be flexible and tractable [@thall1988mixed]. The random effects help model the correlation within clusters and allow for unobserved heterogeneityâ€”differences that are not captured by the measured covariates.

GLMMs are good for:

-  Handling hierarchical or grouped data (e.g., students within classrooms, patients within clinics)[@lee1996hierarchical]


-  Modeling non-normal outcomes, such as:


   -  Binary outcomes (using logistic GLMMs)[@wang2017generalized]


   -  Count data (using Poisson or negative binomial GLMMs)[@candy2000application]


   -  Proportions or rates [@salinas2023generalized]


-  Improving inference by accounting for both fixed effects (predictors of interest) and random effects (random variation across groups)


-  Reducing bias and inflated Type I error rates that can result from ignoring data structure[@thompson2022cluster]


GLMMs are ideal when your data is both complex in structure and involves non-Gaussian response variables, making them indispensable in fields like medicine, ecology, education, and social sciences. Tawiah et al describes zero-inflated Poisson GLMMs, an extension of Poisson GLMM that allows for overdispersion due to a prevalence of zeros in the data, common in health sector data[@tawiah2020zero]. The paper compares a Poisson GLM, a zero-inflated Poisson GLM, a Poisson GLMM, and a zero-inflated Poisson GLMM, applied to clustered maternal mortality data. Another paper by Owili et al utilizes a GLMM to investigate the impact of particulate matter on maternal and infant mortality globally [@owili2020impacts]. They use a Poisson link function and take year and country as random effects to account for differences in global data. 

We wish to analyze the data of federal maternal mortality deaths via VSRR Provisional Maternal Death Counts and Rates dataset by utilizing a General linear mixed model with Poisson link as it is count data. We wish to see if ethnicity (a fixed effect) has any influence upon maternal death per live births(number of live births per 12 month period or year) count by year(random effect). Like other public health or clinical data there will be issues such as correlated observations and overdispersion but GLMM will be utilized to parse through the noise and determine if indeed there are some patterns of maternal mortality among mothers of differing ethnic ties.



## Methods

#### Math Background

GLMMs can be considered an extension of GLMs, wherein a GLM includes the addition of random effects, or an extension of Linear Mixed Models (LMMs), where a linear model with fixed and random effects is extended for non-normal distributions[@salinas2023generalized]. 
Let

- $\mathbf{y}$ be a $Nx1$ column vector outcome variable

- $\mathbf{X}$ be a $Nxp$ matrix for the $p$ predictor variables

- $\boldsymbol{\beta}$ be a $px1$ column vector of the fixed effects coefficients

- $\mathbf{Z}$ is a $Nxq$ matrix of the $q$ random effects

- $\mathbf{u}$ is a $qx1$ vector of random effects, and

- $\boldsymbol{\epsilon}$ is a $Nx1$ column vector of the residuals 

Then the general equation for the model is given by:

$$\mathbf{y}=\mathbf{X}\boldsymbol{\beta}+\mathbf{Z}{u}+\boldsymbol{\epsilon}$$
[@salinas2023generalized].
The GLMM Model process is that the analyis of variance model or the equation is a vector of linear predictors with  of unknown parameters estimates. Each distribution has is its own probability function which we will utilize the Negative Binomial as GLMMs typically include a link function that relates the response variable $\mathbf{y}$ to a linear predictor, $\eta$, which excludes the residuals. So then
$$\boldsymbol{\eta}=\mathbf{X}\boldsymbol{\beta}+\mathbf{Z}\boldsymbol{\lambda}$$
The link function is $g(\cdot)$, where
$$g(E(\mathbf{y}))=\boldsymbol{\eta}$$
where $E(\mathbf{y})$ is the expectation of \mathbf{y}. The choice of link function depends on the outcome distribution. For this paper our data demonstrates a Negative Binomial distribution for overdispered count data, so we will use a log link function.  
$$g(\cdot)=log_e(\cdot)$$
In the GLMM model the  parameter estimates is solved by reducing the negative log likelihood functions[@salinas2023generalized]. The means or the least square means are derivative of the parameter estimates and are found on the model scale. The link function, negative binomial log link, will convert the mean estimates at the model scale to the data scale.
Negative Binomial Distribution:
$$
f(y;k,{\mu})=\frac{\Gamma(y+k)}{\Gamma(k)*(y+1)}\left(\frac{k}{\mu+k}\right)^{k}\left(1-\frac{k}{\mu+k}\right)^{y}
$$
Zuur writes that the negative binomial Distribution has two parameters ${\mu}$ and $k$ [@zuur2009mixed].
The symbol ${\Gamma}$ is defined as ${\Gamma(y+1)=(y+1)!}$
The Mean of Negative Binomial is given: $E(Y)= {\mu}$
The Variance of Negative binomial is given; $Var(Y)= {\mu}+ \left(\frac{\mu^2}{k}\right)$, where second term determines the overdispersion, $k$ is called the dispersion parameter and indirectly determines overdispersion. If $k$ is significantly large relative to ${\mu^2}$ then the second term will approximate to zero and a Poisson distribution may as well be used. However, the smaller the $k$ value the larger the overdispersion may form and then negative binomial is the correct log link to utilize. 

GLMM model process is 

#### Assumptions

Before deciding to use a GLMM for our data, we had to check some assumptions (specific to our negative binomial distributed data). 

- The response variable and the predictors have a linear relationship within the levels of random effects. 
- The response variable is assumed to follow a negative binomial distribution, with $\sigma^2>\mu$.
- The residuals and random effects are independent.
- The random effects are assumed to be normally distributed, with mean 0 and variance $\sigma$.

#### Model Choice
The Negative Binomial distribution's quadratic mean-variance relationship is ideal for overdispersed count data that the Poisson distribution cannot accommodate. Overdispersion is a given for populations due to their heterogeneity that  aggregation processes such as  community clusters form with shared traits such as ethnicity. Our data includes community cluster groups such as ethnicity and age groups.  The negative binomial model is desirable also due to its easily interpretable dispersion parameter as a measure of aggregation and its tractability due to closed form expression of probability mass function which helps in  convenient model inference and estimation.
Since our data is longitudinal, a Negative Binomial GLMM is ideal since measurements are taken over time. We incorporate Year as a random effect because it could explain for variation in our model which could not be explained by our fixed effects such as ethnicity or age group.

We perform the analysis with R[@R] and the packages lme4{@lme4} with function glmer to investigate poisson model or glmer.nb() for negative binomial model and the package glmmTMB{@glmmTMB} with the function, nbinom2(), for negative binomial model. The approximate parameter estimation method uses for glmmTMB uses AGQ or Laplace approximation with Wald Z significance test. The default approximate parameter estimation method for lme4  is Laplace approximation when no quadrature point is used but is pseudo-likelihood method in linearization,and integral approximation and another estimation method is Gauss-Hermite quadrature to approximate the log-likelihood using numerical integration[@salinas2023generalized].

Densities are seen as counts per volume and can be modeled with NB and offset variable[@zuur2009mixed]. We are investigating maternal deaths per live births and while we can use the variable Maternal Mortality rate, it would be less noisy if we used the offset variable log(Live Births). We can also model without the offset and utilize Akaike information Criterion,AIC, to see which is the better model as the smaller the AIC would indicate a better model. A random effect could be month,year, or month/year. Fixed effects could be age groups, ethnicity, and perhaps year. Our choice of random or fixed effects are dependent on the question we which to investigate. 

## Analysis and Results

### Data Exploration and Visualization

The data we used comes from the National Vital Statistics System, an organization that provides national data about births, deaths, marriages, divorces, and fetal deaths. It is a collaboration between the National Center for Health Statistics (NCHS) (a part of the CDC) and state vital records offices. {create citation https://www.cdc.gov/nchs/nvss/about_nvss.htm} This dataset is the Vital Statistics Rapid Release (VSRR) Provisional Maternal Death Counts and Rates, in the form of a .csv file. The dataset contains monthly death counts and death rates  from 2019 to 2024 by race and ethnicity, age and overall. Rates are maternal deaths per 100,000 live births. For this dataset, a maternal death is defined as "the death of a woman while pregnant or within 42 days of termination of pregnancy irrespective of the duration and the site of the pregnancy, from any cause related to or aggravated by the pregnancy or its management, but not from accidental or incidental causes." {create citation https://www.cdc.gov/nchs/nvss/vsrr/provisional-maternal-deaths-rates.htm}

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
library(ggplot2)
library(patchwork) # For combining plots
library(ggpubr)
library(DataExplorer) #For EDA
options(repos = c(CRAN = "https://cloud.r-project.org"))#specify cran mirror
if (!require("lme4")) install.packages("lme4")#if required to install
library(lme4)
##to check if model is overdispersed'
if (!require("performance")) install.packages("performance")#if required to install
library(performance)
##Overdispersion is detected with Poisson model thus we must use negative binomial model
if (!require("glmmTMB")) install.packages("glmmTMB")#if required to install
library(glmmTMB)

if (!require("ggeffects"))install.packages("ggeffects")
library(ggeffects)
```


```{r, warning=FALSE, echo=TRUE}

df <- read.csv("data/VSRR_Provisional_Maternal_Death_Counts_and_Rates_20250726.csv")#loading data
#variables- Maternal.Deaths--outcome variable
#Live.Births---offset variable since it is maternal deaths per live births
#Subgroup- ethnicity and year of mother must be edited --- these are fixed
#Year.of.Death---random effect variable
#Summary
#renaming columns
df<-df%>% 
  rename(Year= Year.of.Death, Month= Month.of.Death, Maternal_Deaths= Maternal.Deaths, Live_Births= Live.Births, Maternal_Mortality_Rate= Maternal.Mortality.Rate, Time_Period= Time.Period, Month_Ending_Date= Month.Ending.Date, Data_As_Of= Data.As.Of) 
str(df) 
filtered_df<- df%>% filter(Maternal_Deaths > 0, Live_Births > 100) #Filtering out rare combinations

test_df <- filtered_df%>%
  select(-Maternal_Mortality_Rate)
  na.omit

```

```{r}
#Summary Statistics

deaths_df <-df %>%
  mutate(
    Ethnicity = case_when(
      Group == "Race and Hispanic origin" ~ Subgroup,
      TRUE ~ NA_character_
    ),
    Age_Group = case_when(
      Group == "Age" ~ Subgroup,
      TRUE ~ NA_character_
    ),
    Is_Total = Subgroup == "Total"
  ,
  Year = as.factor(Year),
  Month= as.factor(Month),
  Ethnicity=as.factor(Ethnicity),
  Age_Group=as.factor(Age_Group))#mutating groups

deaths_df_ethnic<-deaths_df %>%
  filter(!is.na(Ethnicity))%>%
  mutate(Ethnicity = Subgroup)###filter out is total if ethnicity or age group are na

deaths_df_age <-deaths_df %>%
  filter(!is.na(Age_Group)) %>%
  mutate(Age_Group = Subgroup)


merged_deaths_df <-  bind_rows(deaths_df_ethnic, deaths_df_age)  #merge both df

#setting factor levels
deaths_df3 <- merged_deaths_df %>%
  mutate(
    Ethnicity = factor(Ethnicity, levels = c(
      "Asian, Non-Hispanic", "Black, Non-Hispanic", "White, Non-Hispanic",
      "Hispanic", "American Indian or Alaska Native, Non-Hispanic",
      "Native Hawaiian or Other Pacific Islander, Non-Hispanic", "Unknown"
    )),
    Age_Group = factor(Age_Group, levels = c("Under 25 years", "25-39 years", "40 years and over", "Unknown"))
  )

#mutating any NAs with unknown
deaths_df3<- deaths_df3 %>%
   mutate(
    Ethnicity = replace_na(Ethnicity, "Unknown"),
    Age_Group = replace_na(Age_Group, "Unknown")
  )

# make variable in which we combine Year and Month into a for of a date to create later variable, or use month ending date?
deaths_df3$Date <- as.Date(paste(deaths_df3$Year, deaths_df3$Month, "01", sep = "-"))

# Dobbs was decided June 24, 2022
cutoff <- as.Date("2022-06-24")##when Roe v.Wade was overturned

deaths_df3$Dobbs_Era <- ifelse(deaths_df3$Date < cutoff, "Pre-Dobbs", "Post-Dobbs")
deaths_df3$Dobbs_Era <- factor(deaths_df3$Dobbs_Era, levels = c("Pre-Dobbs", "Post-Dobbs"))


df_age_year <- deaths_df %>%
  filter(!is.na(Age_Group), !is.na(Year)) %>%
  group_by(Year, Age_Group) %>%
  summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
df_age_year

df_total_year <-deaths_df%>%
  filter(Group=="Total") %>%
  group_by(Year, Is_Total) %>%
  summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
df_total_year





```
The below chart gives an idea of the missing values in the dataset. It seems like there are many NAs in ethnicity and age group, certainly more than is acceptable. The dataset indicates that Maternal Deaths between 1 and 9 are suppressed for privacy reasons. With more investigation, it appears that the racial/ethnic group "Native Hawaiian or Other Pacific Islander, Non-Hispanic" has NA for all but 2 Maternal Deaths values. We decided to omit this subgroup entirely. There are missing Maternal Mortality Rate entries in "American Indian or Alaska Native, Non-Hispanic", which will not be an issue as we have decided not to use rate in our model ( though we will examine it during our Exploratory Data Analysis). Finally, there are six NA Maternal Deaths also in the "American Indian or Alaska Native, Non-Hispanic" category, a number that is reasonable to omit. 
```{r}
plot_missing(deaths_df)
plot_missing(test_df)
```

Since our data is longitudinal, it is easy to visualize with graphs. Below is a bar chart that shows the distibution of Maternal Deaths by racial/ethnic group. The counts indicated the sum of the Maternal Deaths for each group over the span of the data (2019-2024). 
```{r}
#Data Exploration Graph 1
colors=c('yellow','orange', 'blue', 'red', 'green')
df_ethnicity <- deaths_df %>%
    filter(!is.na(Ethnicity)) %>%
    group_by(Ethnicity) %>%
    summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
#barplot(df_ethnicity$Maternal_Deaths,names.arg=c('Am In/Ala', 'Asian, NH','Black, #NH','Hispanic','White,NH'),main="Maternal Mortality Totals 2019-2024 by #Ethnicity",col=colors,xlab='Ethnicity',ylab='Maternal Deaths')
```
This graph shows the total Maternal Deaths for each year. The counts for year are the sum of the monthly data.
```{r}
#Data Exploration Graph 2
df_tot_year_ts<-ts(df_total_year$Maternal_Deaths, start = c(2019), frequency = 1)
plot.ts(df_tot_year_ts,main='Yearly Total Maternal Deaths 2019-2024',xlab='Year',ylab='Maternal Deaths',col='navy')


df_tot_year_rate <- filtered_df%>%
  filter(Group=='Total')%>%
  select(Maternal_Mortality_Rate)
df_tot_year_rate_ts<-ts(df_tot_year_rate$Maternal_Mortality_Rate, start = c(2019,1), frequency = 12)
plot.ts(df_tot_year_rate_ts,main='Monthly Total Maternal Mortality Rate 2019-2024',xlab='Year',ylab='Maternal Deaths per 100,000 Live Births',col='navy')




total_df <- deaths_df%>%
  filter(Group=='Total')
total_ts <- ts(total_df$Maternal_Deaths,start=c(2019,1),frequency=12)
plot.ts(total_ts,main='Monthly Total Maternal Deaths 2019-2024',ylab='Maternal Deaths',xlab='Time',col='navy')  



His <- filtered_df%>%
  filter(Subgroup=='Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename(Hispanic=Maternal_Deaths)
bl <- filtered_df%>%
  filter(Subgroup=='Black, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('Black_Non-Hispanic' = Maternal_Deaths)
wh <- filtered_df%>%
  filter(Subgroup=='White, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('White_Non-Hispanic'=Maternal_Deaths)
as <- filtered_df%>%
  filter(Subgroup=='Asian, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('Asian_Non-Hispanic'=Maternal_Deaths)
aina <- df%>%
  filter(Subgroup=='American Indian or Alaska Native, Non-Hispanic')%>%
  select(Maternal_Deaths)%>% 
  rename('American_Indian_or_Alaska_Native, Non-Hispanic'=Maternal_Deaths)
ethn_ts <- bind_cols(His,bl,wh,as,aina) 
ethn_ts <- ts(ethn_ts, start=c(2019,1), frequency = 12)
colors=c('red','blue','green','orange','yellow')
plot.ts(ethn_ts, plot.type='single',main='Monthly Maternal Deaths by Ethnicity 2019-2024', ylab='Maternal Deaths',xlab='Time',col=colors)
legend("topleft",                     
       legend = c("Hispanic", "Black, Non-Hispanic", "White, Non-Hispanic",'Asian, Non-Hispanic','American Indian, Alaska Native, Non-Hisp'),  # Labels
       col = colors,                   
       lty = 1,                        
       lwd = 2,                     
       bty = "n",
       cex = 0.8)                      



HisR <- filtered_df%>%
  filter(Subgroup=='Hispanic')%>%
  select(Maternal_Mortality_Rate)%>%
  rename(Hispanic=Maternal_Mortality_Rate)
blR <- filtered_df%>%
  filter(Subgroup=='Black, Non-Hispanic')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('Black_Non-Hispanic' = Maternal_Mortality_Rate)
whR <- filtered_df%>%
  filter(Subgroup=='White, Non-Hispanic')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('White_Non-Hispanic'=Maternal_Mortality_Rate)
asR <- filtered_df%>%
  filter(Subgroup=='Asian, Non-Hispanic')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('Asian_Non-Hispanic'=Maternal_Mortality_Rate)
ainaR <- df%>%
  filter(Subgroup=='American Indian or Alaska Native, Non-Hispanic')%>%
  select(Maternal_Mortality_Rate)%>% 
  rename('American_Indian_or_Alaska_Native, Non-Hispanic'=Maternal_Mortality_Rate)
ethnR_ts <- bind_cols(HisR,blR,whR,asR,ainaR) 
ethnR_ts <- ts(ethnR_ts, start=c(2019,1), frequency = 12)
colors=c('red','blue','green','orange','yellow')
plot.ts(ethnR_ts, plot.type='single',main='Monthly Maternal Mortality Rate by Ethnicity 2019-2024', ylab='Maternal Deaths per 100,000 Live Births',xlab='Time',col=colors)
legend("topleft",                     
       legend = c("Hispanic", "Black, Non-Hispanic", "White, Non-Hispanic",'Asian, Non-Hispanic','American Indian, Alaska Native, Non-Hisp'),  # Labels
       col = colors,                   
       lty = 1,                        
       lwd = 2,                     
       bty = "n",
       cex = 0.7)            



ageu25 <- deaths_df%>%
  filter(Subgroup=='Under 25 years')%>%
  select(Maternal_Deaths)%>%
  rename('Under_25_years'=Maternal_Deaths)
age25 <- filtered_df%>%
  filter(Subgroup=='25-39 years')%>%
  select(Maternal_Deaths)%>%
  rename('25-39_years' = Maternal_Deaths)
ageo40 <- filtered_df%>%
  filter(Subgroup=='40 years and over')%>%
  select(Maternal_Deaths)%>%
  rename('40_years_and_over'=Maternal_Deaths)
age_ts <- bind_cols(ageu25,age25,ageo40) 
age_ts <- ts(age_ts, start=c(2019,1), frequency = 12)
colors=c('red','blue','green')
plot.ts(age_ts, plot.type='single',main='Monthly Maternal Deaths by Age Group 2019-2024', ylab='Maternal Deaths',xlab='Time',col=colors)
legend("topleft",                     
       legend = c("Under 25 Years", "25-39 Years", "40 Years and over"),  # Labels
       col = colors,                   
       lty = 1,                        
       lwd = 2,                     
       bty = "n",
       cex = 0.8) 



ageu25R <- filtered_df%>%
  filter(Subgroup=='Under 25 years')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('Under_25_years'=Maternal_Mortality_Rate)
age25R <- filtered_df%>%
  filter(Subgroup=='25-39 years')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('25-39_years' = Maternal_Mortality_Rate)
ageo40R <- filtered_df%>%
  filter(Subgroup=='40 years and over')%>%
  select(Maternal_Mortality_Rate)%>%
  rename('40_years_and_over'=Maternal_Mortality_Rate)
ageR_ts <- bind_cols(ageu25R,age25R,ageo40R) 
ageR_ts <- ts(ageR_ts, start=c(2019,1), frequency = 12)
colors=c('red','blue','green')
plot.ts(ageR_ts, plot.type='single',main='Monthly Maternal Mortality Rate by Age Group 2019-2024', ylab='Maternal Deaths per 100,000 live Births',xlab='Time',col=colors)
legend("topleft",                     
       legend = c("Under 25 Years", "25-39 Years", "40 Years and over"),  # Labels
       col = colors,                   
       lty = 1,                        
       lwd = 2,                     
       bty = "n",
       cex = 0.8) 
```

```{r}
plot_histogram(deaths_df_ethnic$Maternal_Deaths,title='Histogram of Maternal Deaths - Ethnicity')
plot_histogram(deaths_df_age$Maternal_Deaths, title='Histogram of Maternal Deaths - Age')
plot_histogram(total_df$Maternal_Deaths,title='Histogram of Maternal Deaths - Total')
```

```{r}
#check overdispersion by for ethnicity data
deaths_df_ethnic %>% summarize(mean(Maternal_Deaths),
var(Maternal_Deaths))
#check overdispersion for age data
deaths_df_age %>% summarize(mean(Maternal_Deaths),var(Maternal_Deaths))
#check overdispersion for total data
total_df %>% summarize(mean(Maternal_Deaths),
var(Maternal_Deaths))
```

<<<<<<< HEAD
=======

>>>>>>> 5ff3583d31d40c93aaa9005a06c34bf67126bfd1

```{r}
poissonmodel_glmm_all <- glmer(Maternal_Deaths ~ Ethnicity +Age_Group+ Dobbs_Era+(1|Year),
                              offset=log(Live_Births),
                              family = poisson(link = "log"), 
                              data = deaths_df3)
poissonmodel_glmm_all
```



```{r}
check_overdispersion(poissonmodel_glmm_all)

```
##overdispersion still detected





```{r}
##with offset # all fixed effects
all_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Ethnicity + Age_Group +Dobbs_Era+ (1|Year),
  offset=log(Live_Births),
  family = nbinom2,
  data = deaths_df3
)
summary(all_glmmodel_nb)

```





```{r}
ethnicity_agegroup_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Ethnicity+ Age_Group + (1|Year),
  offset=log(Live_Births),
  family = nbinom2,
  data = deaths_df3
)
summary(ethnicity_agegroup_glmmodel_nb)
```


```{r}

##with no offset # all fixed effects #with not offset we can just use maternal mmortality rate per 100,0000 live_births
allno_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Ethnicity + Age_Group+ Dobbs_Era + (1 |Year),
  family = nbinom2,
  data = deaths_df3
)
summary(allno_glmmodel_nb)

```

```{r}
ethnicity_agegroupno_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Ethnicity+ Age_Group + (1 |Year),
  family = nbinom2,
  data = deaths_df3
)
summary(ethnicity_agegroupno_glmmodel_nb)
```





```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!require("performance"))install.packages("performance")#if required to install
library(performance)

if (!require("DHARMa"))install.packages("DHARMa")#if required to install
library(DHARMa)

if (!require("sjPlot"))install.packages("sjPlot")#if required to install
library(sjPlot, quietly = FALSE, warn.conflicts = FALSE)
if (!require("MuMIN"))install.packages("MuMIn")
library(MuMIn)
if (!require("bbmle"))install.packages("bbmle")
library("bbmle")
```





```{r}
bbmle::AICtab(all_glmmodel_nb,allno_glmmodel_nb, ethnicity_agegroup_glmmodel_nb, ethnicity_agegroupno_glmmodel_nb)


```

It is said that even though not using offset has lower A1c it is incorrect model because it does not include live births or correct variance structure so I will be testing both. While AIC for not including offset is lower, assumptions are violated. When omitting offset then all observations are assumed to have same exposure. Different years or ethnicity can have different numbers of births. Offset gives rate per exposure even if AIC is higher.

```{r}


MuMIn::model.sel(all_glmmodel_nb,allno_glmmodel_nb, ethnicity_agegroup_glmmodel_nb, ethnicity_agegroupno_glmmodel_nb)

```












```{r}
performance::check_model(allno_glmmodel_nb, verbose=TRUE, residual_type = "normal")##interesting
performance::r2(allno_glmmodel_nb)
check_singularity(allno_glmmodel_nb)
check_collinearity(allno_glmmodel_nb)
```



`
```{r}
performance::check_model(all_glmmodel_nb, verbose=TRUE, residual_type = "normal")##interesting
performance::r2(all_glmmodel_nb)
check_singularity(all_glmmodel_nb)
check_collinearity(all_glmmodel_nb)
```





```{r}
resid_pearson <- residuals(allno_glmmodel_nb, type = "pearson")
plot(resid_pearson ~ fitted(allno_glmmodel_nb), main = "Pearson residuals vs Fitted for model without offset")
abline(h = 0, col = "red")
```


```{r}

resid_pearson <- residuals(all_glmmodel_nb, type = "pearson")
plot(resid_pearson ~ fitted(all_glmmodel_nb), main = "Pearson residuals vs Fitted for model with offset")
abline(h = 0, col = "red")
```


```{r}
overdisp_fun <- function(allno_glmmodel_nb) {
  rdf <- df.residual(allno_glmmodel_nb)
  rp <- residuals(allno_glmmodel_nb, type = "pearson")
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq / rdf
  pval <- pchisq(Pearson.chisq, df = rdf, lower.tail = FALSE)
  c(chisq = Pearson.chisq, ratio = prat, rdf = rdf, p = pval)
}

overdisp_fun(allno_glmmodel_nb)

#ratio is around 1 which is good and not too indicative of overdispersion
#pp-value is greater that P<0.005 so that means there is no significant overdispersion
```

```{r}

overdisp_fun <- function(all_glmmodel_nb) {
  rdf <- df.residual(all_glmmodel_nb)
  rp <- residuals(all_glmmodel_nb, type = "pearson")
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq / rdf
  pval <- pchisq(Pearson.chisq, df = rdf, lower.tail = FALSE)
  c(chisq = Pearson.chisq, ratio = prat, rdf = rdf, p = pval)
}

overdisp_fun(all_glmmodel_nb)

#ratio is around 1 which is good and not too indicative of overdispersion
#pp-value is greater that P<0.005 so that means there is no significant overdispersion
```


```{r}

arm::binnedplot(fitted(allno_glmmodel_nb), 
           residuals(allno_glmmodel_nb, type = "response"), 
           main = "Binned residual plot in model without offset")
# fan shape  heteroskedasticity (non-constant variance)- coon when with count data
```
```{r}
arm::binnedplot(fitted(all_glmmodel_nb), 
           residuals(all_glmmodel_nb, type = "response"), 
           main = "Binned residual plot in model with offset")
# fan shape  heteroskedasticity (non-constant variance)- coon when with count data
```








```{r}
re <- ranef(allno_glmmodel_nb)
cond_re <- re$cond
year_re <- as.data.frame(cond_re$Year)
year_re$Year <- rownames(year_re)

ggplot(year_re, aes(x = factor(Year), y = `(Intercept)`)) +
  geom_point(size = 3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Random Effect Intercepts by Year in model without offset",
       x = "Year",
       y = "Random Effect Estimate (Intercept)") +
  theme_minimal()


#dashed zero is the overall random intercept
# points above zero - years with above average random effect
#points below zero- years below average random effect
```


```{r}
re <- ranef(all_glmmodel_nb)
cond_re <- re$cond
year_re <- as.data.frame(cond_re$Year)
year_re$Year <- rownames(year_re)

ggplot(year_re, aes(x = factor(Year), y = `(Intercept)`)) +
  geom_point(size = 3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Random Effect Intercepts by Year in model with offset",
       x = "Year",
       y = "Random Effect Estimate (Intercept)") +
  theme_minimal()


#dashed zero is the overall random intercept
# points above zero - years with above average random effect
#points below zero- years below average random effect
```


```{r}
sjPlot::plot_model(allno_glmmodel_nb, type = "re") #no extreme points with random effects
```

```{r}
sjPlot::tab_model(allno_glmmodel_nb)##coefficients of not using offset is not good and can effect estimates

```

```{r}
sjPlot::plot_model(all_glmmodel_nb, type = "re") #no extreme points with random effects #with offset
```

```{r}
sjPlot::tab_model(all_glmmodel_nb)#withh offset

```

```{r}
# pseudo overdispersion test
overdisp_fun <- function(model) {
  rdf <- df.residual(model)
  rp <- residuals(model, type = "pearson")
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq / rdf
  pval <- pchisq(Pearson.chisq, df = rdf, lower.tail = FALSE)
  c(chisq = Pearson.chisq, ratio = prat, rdf = rdf, p = pval)
}
overdisp_fun(all_glmmodel_nb )
overdisp_fun(allno_glmmodel_nb)#slightly worse
```


```{r}

#The response variable and the predictors have a linear relationship within the levels of random effect
# Base partial residuals (approximate)

resid_vals<-resid(allno_glmmodel_nb,type = "pearson")
fitted_vals <- predict(allno_glmmodel_nb,type = "response")

x <- jitter(fitted_vals)
y<-resid_vals

plot(x, y, main = "Residuals vs Fitted with LOESS model without offset") #LOESS is smoother line
abline(h = 0, col = "red")#where residuals equal zero
lines(lowess(x, y), col = "blue", lwd = 2)#Blue LOESS line stays flat around 0


```

```{r}


#The response variable and the predictors have a linear relationship within the levels of random effect
# Base partial residuals (approximate)

resid_vals<-resid(all_glmmodel_nb,type = "pearson")
fitted_vals <- predict(all_glmmodel_nb,type = "response")

x <- jitter(fitted_vals)
y<-resid_vals

plot(x, y, main = "Residuals vs Fitted with LOESS model with offset") #LOESS is smoother line
abline(h = 0, col = "red")#where residuals equal zero
lines(lowess(x, y), col = "blue", lwd = 2)#Blue LOESS line stays flat around 0


```



```{r}
#Normality of Random effects

#Points fall close to red line so random effects are approximately normal


re_year <- ranef(allno_glmmodel_nb)$cond$Year[["(Intercept)"]] #extract year random reffect intercepts as numeric

qqnorm(re_year, main = "Q-Q Plot of Random Effect of model without offset (Year)")
qqline(re_year, col = "red")#points should roughly lie by this line if normal
hist(re_year, main = "Histogram of Random Effectsof model without offset", xlab = "Random effect (Year)")

df_re <- data.frame(re = re_year)

ggplot(df_re, aes(x = re_year)) +
  geom_density(fill = "skyblue", alpha = 0.5) +#density curve of random effect distribution
  stat_function(fun = dnorm, args = list(mean = mean(re_year), sd = sd(re_year)),
                color = "red", linetype = "dashed") +###red is ideal normal distribution with same means and standard deviation
  ggtitle("Density of Random Effect f model without offset (Year) with Normal Curve")

#since most of blue density is within red line 
#The random effect of year is approximately normal with some mild deviations which is common with count models 
```

```{r}
#Normality of Random effects

#Points fall close to red line so random effects are approximately normal


re_year <- ranef(all_glmmodel_nb)$cond$Year[["(Intercept)"]] #extract year random reffect intercepts as numeric

qqnorm(re_year, main = "Q-Q Plot of Random Effect of model without offset (Year)")
qqline(re_year, col = "red")#points should roughly lie by this line if normal
hist(re_year, main = "Histogram of Random Effectsof model without offset", xlab = "Random effect (Year)")

df_re <- data.frame(re = re_year)

ggplot(df_re, aes(x = re_year)) +
  geom_density(fill = "skyblue", alpha = 0.5) +#density curve of random effect distribution
  stat_function(fun = dnorm, args = list(mean = mean(re_year), sd = sd(re_year)),
                color = "red", linetype = "dashed") +###red is ideal normal distribution with same means and standard deviation
  ggtitle("Density of Random Effect f model without offset (Year) with Normal Curve")

#since most of blue density is within red line 
#The random effect of year is approximately normal with some mild deviations which is common with count models 
```

```{r}
#  Independence of Residuals and Random Effects
#random effects of year
#residuals leftover variation after accounting for fixed and random effects
#random effects show between group variation (how each group's slope or intercet differs)
#if are independent then model is correctly partiioning information
#residuals capture individual level random noise not exxplained by model and if
#there is no tie between residuals or random effects it upholds key assumption 
#that the random effects and residuals are independent of each other
re_year <- ranef(allno_glmmodel_nb)$cond$Year[[1]]  # 'cond' = conditional mode


qqnorm(re_year, main = "Q-Q Plot of Random Intercepts in odel without offset(Year)")#plots quantiles of random intercept estimates vs quantiles of normal distriibution
qqline(re_year, col = "red")##dots follow reference line that shows where points would lie if distribution was normal, random intercepts are normally distributed



```


```{r}
#  Independence of Residuals and Random Effects
#random effects of year
#residuals leftover variation after accounting for fixed and random effects
#random effects show between group variation (how each group's slope or intercet differs)
#if are independent then model is correctly partiioning information
#residuals capture individual level random noise not exxplained by model and if
#there is no tie between residuals or random effects it upholds key assumption 
#that the random effects and residuals are independent of each other
re_year <- ranef(allno_glmmodel_nb)$cond$Year[[1]]  # 'cond' = conditional mode


qqnorm(re_year, main = "Q-Q Plot of Random Intercepts in model with offset (Year)")#plots quantiles of random intercept estimates vs quantiles of normal distriibution
qqline(re_year, col = "red")##dots follow reference line that shows where points would lie if distribution was normal, random intercepts are normally distributed



```



```{r}
install.packages("ggeffects")  # if not yet installed
library(ggeffects)

#  predictions by ethnicity
pred_eth <- ggpredict(allno_glmmodel_nb, terms = "Ethnicity")
plot(pred_eth) + ggtitle("Predicted Maternal Deaths by Ethnicity")

#  predictions by Age Group
pred_age <- ggpredict(allno_glmmodel_nb, terms = "Age_Group")
plot(pred_age) + ggtitle("Predicted Maternal Deaths by Age Group")

# Predictions by Dobbs Era
pred_dobbs <- ggpredict(allno_glmmodel_nb, terms = "Dobbs_Era")
plot(pred_dobbs) + ggtitle("Predicted Maternal Deaths by Dobbs Era")

```


























```{r}

#errror because reokkacenebt g=has 5591 values and data has 675
library(ggplot2)
library(ggeffects)

# Add predicted values to your dataset
deaths_df3$predicted <- predict(all_glmmodel_nb, type = "response")

ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = predicted, color = Ethnicity)) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point") +
  labs(title = "Trend of Predicted Maternal Deaths by Ethnicity Over Time",
       x = "Year", y = "Predicted Maternal Deaths") +
  theme_minimal()

```

```{r}
library(ggplot2)
ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = Maternal_Deaths, color = Ethnicity)) +
  stat_summary(fun = sum, geom = "line", size = 1) +
  stat_summary(fun = sum, geom = "point") +
  labs(title = "Observed Maternal Deaths Over Time by Ethnicity",
       x = "Year", y = "Observed Maternal Deaths") +
  theme_minimal()
```

```{r}
library(ggplot2)
library(ggeffects)

ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = Maternal_Mortality_Rate, color = Ethnicity)) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point") +
  labs(
    title = "Maternal Mortality Rate Over Time by Ethnicity",
    x = "Year",
    y = "Maternal Mortaity Rate (per 100,000 live births)"
  ) +
  theme_minimal()
```

```{r}
library(ggplot2)
library(ggeffects)
ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = Maternal_Mortality_Rate, color = Ethnicity)) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point") +
  labs(
    title = "Maternal Mortality Rate Over Time by Ethnicity",
    x = "Year",
    y = "Maternal Mortaity Rate (per 100,000 live births)"
  ) +
  theme_minimal()

#I tried to do age group but would not work
```

```{r}
library(ggplot2)
library(ggeffects)
ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = Maternal_Mortality_Rate, color = Age_Group)) +
  stat_summary(fun =mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point") +
  labs(title = "Maternal Mortality Rate Over Time by Age Group",
       x = "Year", y = "Maternal Mortaity Rate (per 100,000 live births)") +
  theme_minimal()
```

```{r}
library(ggplot2)
ggplot(deaths_df3, aes(x = as.numeric(as.character(Year)), y = Maternal_Mortality_Rate, color = Dobbs_Era)) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  stat_summary(fun = mean, geom = "point") +
  labs(title = "Observed Maternal Deaths Over Time by Dobbs Era",
       x = "Year", y = "Observed Maternal Deaths") +
  theme_minimal()
```



### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**



### Conclusion

-   Summarize your key findings.
WE did not find what we expected but the data is provisional. 
-   Discuss the implications of your results.

## References
