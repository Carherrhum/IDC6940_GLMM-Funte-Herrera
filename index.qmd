---
title: "GLMM Maternal Mortality Federally- Summer 2025"
subtitle: "This is a Report Template"
author: "Carolyn Herrera & Catherine Funte (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction


Generalized Linear Mixed Models (GLMMs) are a flexible class of statistical models that combine the features of two powerful tools: Generalized Linear Models (GLMs) and Mixed-Effects Models[@agresti2015foundations]. Like GLMs, GLMMs can model non-normal outcome variables, such as binary, count, or proportion data. However, they go a step further by incorporating random effects, which account for variation due to grouping or clustering in the data, correlated observations, and overdispersion. The GLMM method can work with complex data structures such as temporal correlation, spatial correlation , nested data, heterogeneity of variance, and repeated measurement[@zuur2009mixed].  

In practical terms, GLMMs are especially useful when data points are not independent, such as when students are nested within schools, patients are treated within hospitals, or repeated measures are taken from the same subject over time. For example, Thall wrote that issues with longitudinal clinical trial basic count data from repeated measures taken from the same subject over time will have problems detecting comparable between subject outcomes because it can be difficult to determine if outcomes are time dependent or due to treatment groups, thus a general linear mixed model method may be utilized to represent dependence upon each patient, incorporate covariate data, create time as a function, account for variability between patients,and  be flexible and tractable [@thall1988mixed]. The random effects help model the correlation within clusters and allow for unobserved heterogeneityâ€”differences that are not captured by the measured covariates.

GLMMs are good for:

-  Handling hierarchical or grouped data (e.g., students within classrooms, patients within clinics)[@lee1996hierarchical]


-  Modeling non-normal outcomes, such as:


   -  Binary outcomes (using logistic GLMMs)[@wang2017generalized]


   -  Count data (using Poisson or negative binomial GLMMs)[@candy2000application]


   -  Proportions or rates [@salinas2023generalized]


-  Improving inference by accounting for both fixed effects (predictors of interest) and random effects (random variation across groups)


-  Reducing bias and inflated Type I error rates that can result from ignoring data structure[@thompson2022cluster]


GLMMs are ideal when your data is both complex in structure and involves non-Gaussian response variables, making them indispensable in fields like medicine, ecology, education, and social sciences. Tawiah et al describes zero-inflated Poisson GLMMs, an extension of Poisson GLMM that allows for overdispersion due to a prevalence of zeros in the data, common in health sector data[@tawiah2020zero]. The paper compares a Poisson GLM, a zero-inflated Poisson GLM, a Poisson GLMM, and a zero-inflated Poisson GLMM, applied to clustered maternal mortality data. Another paper by Owili et al utilizes a GLMM to investigate the impact of particulate matter on maternal and infant mortality globally [@owili2020impacts]. They use a Poisson link function and take year and country as random effects to account for differences in global data. 

We wish to analyze the data of federal maternal mortality deaths via VSRR Provisional Maternal Death Counts and Rates dataset by utilizing a General linear mixed model with Poisson link as it is count data. We wish to see if ethnicity (a fixed effect) has any influence upon maternal death per live births(number of live births per 12 month period or year) count by year(random effect). Like other public health or clinical data there will be issues such as correlated observations and overdispersion but GLMM will be utilized to parse through the noise and determine if indeed there are some patterns of maternal mortality among mothers of differing ethnic ties.



## Methods

#### Math Background

GLMMs can be considered an extension of GLMs, wherein a GLM includes the addition of random effects, or an extension of Linear Mixed Models (LMMs), where a linear model with fixed and random effects is extended for non-normal distributions[@salinas2023generalized]. 
Let

- $\mathbf{y}$ be a $Nx1$ column vector outcome variable

- $\mathbf{X}$ be a $Nxp$ matrix for the $p$ predictor variables

- $\boldsymbol{\beta}$ be a $px1$ column vector of the fixed effects coefficients

- $\mathbf{Z}$ is a $Nxq$ matrix of the $q$ random effects

- $\mathbf{u}$ is a $qx1$ vector of random effects, and

- $\boldsymbol{\epsilon}$ is a $Nx1$ column vector of the residuals 

Then the general equation for the model is given by:

$$\mathbf{y}=\mathbf{X}\boldsymbol{\beta}+\mathbf{Z}{u}+\boldsymbol{\epsilon}$$
[@salinas2023generalized].
The GLMM Model process is that the analyis of variance model or the equation is a vector of linear predictors with  of unknown parameters estimates. Each distribution has is its own probability function which we will utilize the Negative Binomial as GLMMs typically include a link function that relates the response variable $\mathbf{y}$ to a linear predictor, $\eta$, which excludes the residuals. So then
$$\boldsymbol{\eta}=\mathbf{X}\boldsymbol{\beta}+\mathbf{Z}\boldsymbol{\lambda}$$
The link function is $g(\cdot)$, where
$$g(E(\mathbf{y}))=\boldsymbol{\eta}$$
where $E(\mathbf{y})$ is the expectation of \mathbf{y}. The choice of link function depends on the outcome distribution. For this paper our data demonstrates a Negative Binomial distribution for overdispered count data, so we will use a log link function.  
$$g(\cdot)=log_e(\cdot)$$
In the GLMM model the  parameter estimates is solved by reducing the negative log likelihood functions[@salinas2023generalized]. The means or the least square means are derivative of the parameter estimates and are found on the model scale. The link function, negative binomial log link, will convert the mean estimates at the model scale to the data scale.
Negative Binomial Distribution:
$$
f(y;k,{\mu})=\frac{\Gamma(y+k)}{\Gamma(k)*(y+1)}\left(\frac{k}{\mu+k}\right)^{k}\left(1-\frac{k}{\mu+k}\right)^{y}
$$
Zuur writes that the negative binomial Distribution has two parameters ${\mu}$ and $k$ [@zuur2009mixed].
The symbol ${\Gamma}$ is defined as ${\Gamma(y+1)=(y+1)!}$
The Mean of Negative Binomial is given: $E(Y)= {\mu}$
The Variance of Negative binomial is given; $Var(Y)= {\mu}+ \left(\frac{\mu^2}{k}\right)$, where second term determines the overdispersion, $k$ is called the dispersion parameter and indirectly determines overdispersion. If $k$ is significantly large relative to ${\mu^2}$ then the second term will approximate to zero and a Poisson distribution may as well be used. However, the smaller the $k$ value the larger the overdispersion may form and then negative binomial is the correct log link to utilize. 

GLMM model process is 

#### Assumptions

Before deciding to use a GLMM for our data, we had to check some assumptions (specific to our negative binomial distributed data). 

- The response variable and the predictors have a linear relationship within the levels of random effects. 
- The response variable is assumed to follow a negative binomial distribution, with $\sigma^2>\mu$.
- The residuals and random effects are independent.
- The random effects are assumed to be normally distributed, with mean 0 and variance $\sigma$.

#### Why Chosen for 
The Negative Binomial distribution is ideal for overdispersed count data in a fashion the poisson distribution cannot accommodate due Negative Binomial distribution's quadratic nature of mean-variance relationship. Overdispersion is a given for populations due to their heterogeneity that  aggregation processes such as  community clusters form with shared traits such as ethnicity. Our data includes community cluster groups such as ethnicity and age groups.  The negative binomial model is desirable also due to its easily intrepretable dispersion parameter as a measure of aggregation and its tractability due to closed form expression of probability mass function which helps in  convenient model inference and estimation.
Such as our data is longitudinal a Negative Binomial GLMM is ideal since measurements are taken over time. We incoporate Year as a random effect because it could explain for variation in our model which could not be explained by our fixed effects such as ethnicity or age groups.

WE shall analyze by using R[@R] and the packages lme4{@lme4} with function glmer to investigate poisson model or glmer.nb() for negative binomial model and the package glmmTMB{@glmmTMB} with the function, nbinom2(), for negative binomial model. The approximate parameterestimation method uses for glmmTMB uses AGQ or Laplace approximation with Wald Z significance test. The approximate parameter estimation method for lme4 default is Laplace approximation when no quadrature point is used but is pseudo-likelihood method in linearization,and integral approximation the and another estimation method is Gauss-Hermite quadrature to approximate the log-likelihood using numerical integration[@salinas2023generalized].

Densities are seen as counts per volume and can be modeled with NB and offset variable[@zuur2009mixed]. We are investigation maternal deaths per live births and while we can use the variable rate, it would be less noisy if we used the offset variable log(Live Births). We can also model without the offset and utilize Akaike information criterion,AIC, to see which is the better model as the smaller the AIC would indicate a better model. A random effect could be month,year, or month/year. Fixed effects could be age groups, ethnicity, and perhaps year. Our choice of random or fixed effects are dependent on the question we which to investigate. 

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

Data source is the VSSR Maternal Mortality. We collected by uploaded csv file into R. 

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
library(ggplot2)
library(patchwork) # For combining plots
library(ggpubr)
```

```{r, warning=FALSE, echo=TRUE}

df <- read.csv("data/VSRR_Provisional_Maternal_Death_Counts_and_Rates_20250726.csv")#loading data
#variables- Maternal.Deaths--outcome variable
#Live.Births---offset variable since it is maternal deaths per live births
#Subgroup- ethnicity and year of mother must be edited --- these are fixed
#Year.of.Death---random effect variable
#Summary
#renaming columns
df<-df%>% 
  rename(Year= Year.of.Death, Month= Month.of.Death, Maternal_Deaths= Maternal.Deaths, Live_Births= Live.Births, Maternal_Mortality_Rate= Maternal.Mortality.Rate, Time_Period= Time.Period, Month_Ending_Date= Month.Ending.Date, Data_As_Of= Data.As.Of) 
  
filtered_df<- df%>% filter(Maternal_Deaths > 0, Live_Births > 100) #Filtering out rare combinations
  
test_df <- na.omit(filtered_df)#filtered na

```

```{r}
#Summary Statistics
deaths_df <-test_df %>%
  mutate(
    Ethnicity = case_when(
      Group == "Race and Hispanic origin" ~ Subgroup,
      TRUE ~ NA_character_
    ),
    Age_Group = case_when(
      Group == "Age" ~ Subgroup,
      TRUE ~ NA_character_
    ),
    Is_Total = Subgroup == "Total"
  ,
  Year = as.factor(Year),
  Month= as.factor(Month),
  Ethnicity=as.factor(Ethnicity),
  Age_Group=as.factor(Age_Group))#mutating groups

deaths_df_ethnic<-deaths_df %>%
  filter(!is.na(Ethnicity))###filter out is total if ethnicity or age group are na

deaths_df_age <-deaths_df %>%
  filter(!is.na(Age_Group))
merged_deaths_df <-  bind_rows(deaths_df_ethnic, deaths_df_age) %>%
  distinct() 
deaths_df2<-merged_deaths_df %>%
  filter(!(Is_Total & (is.na(Ethnicity) | is.na(Age_Group))))
##to get total deaths per year by ethnicity
  df_ethnicity_year <- deaths_df %>%
    filter(!is.na(Ethnicity), !is.na(Year)) %>%
    group_by(Year, Ethnicity) %>%
    summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
  df_ethnicity_year

df_age_year <- deaths_df %>%
  filter(!is.na(Age_Group), !is.na(Year)) %>%
  group_by(Year, Age_Group) %>%
  summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
df_age_year

df_total_year <-deaths_df%>%
  filter(Group=="Total") %>%
  group_by(Year, Is_Total) %>%
  summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
df_total_year

deaths_df2<-deaths_df %>%
  filter(!(Is_Total & (is.na(Ethnicity) | is.na(Age_Group))))###filter out is total if ethnicity or age when total is true

```
```{r}
#Data Exploration Graphs
df_ethnicity <- deaths_df %>%
    filter(!is.na(Ethnicity)) %>%
    group_by(Ethnicity) %>%
    summarise(Maternal_Deaths = sum(Maternal_Deaths, na.rm = TRUE))
barplot(df_ethnicity$Maternal_Deaths,names.arg=c('Am Ind/Al Nat', 'Asian, NH','Black, NH','Hispanic','White,NH'),main="Maternal Mortality Totals 2019-2024 by Ethnicity")


df_tot_year_ts<-ts(df_total_year$Maternal_Deaths, start = c(2019), frequency = 1)
plot.ts(df_tot_year_ts,main='Yearly Total Maternal Deaths 2019-2024',xlab='Year',ylab='Maternal Deaths')


total_ts <- deaths_df%>%
  filter(Group=='Total')
total_ts <- ts(total_ts$Maternal_Deaths,start=c(2019,1),frequency=12)
plot.ts(total_ts,main='Monthly Total Maternal Deaths 2019-2024',ylab='Maternal Deaths',xlab='Time')  

His <- filtered_df%>%
  filter(Subgroup=='Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename(Hispanic=Maternal_Deaths)
bl <- filtered_df%>%
  filter(Subgroup=='Black, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('Black_Non-Hispanic' = Maternal_Deaths)
wh <- filtered_df%>%
  filter(Subgroup=='White, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('White_Non-Hispanic'=Maternal_Deaths)
as <- filtered_df%>%
  filter(Subgroup=='Asian, Non-Hispanic')%>%
  select(Maternal_Deaths)%>%
  rename('Asian_Non-Hispanic'=Maternal_Deaths)
aina <- df%>%
  filter(Subgroup=='American Indian or Alaska Native, Non-Hispanic')%>%
  select(Maternal_Deaths)%>% 
  rename('American_Indian_or_Alaska_Native, Non-Hispanic'=Maternal_Deaths)
ethn_ts <- bind_cols(His,bl,wh,as,aina) 
ethn_ts[is.na(ethn_ts)] <- 5 #NA values are between 1 and 9 and left empty for privacy reasons, replaced with mean of 5
ethn_ts <- ts(ethn_ts, start=c(2019,1), frequency = 12)
plot.ts(ethn_ts, plot.type='single',main='Monthly Maternal Deaths by Ethnicity 2019-2024', ylab='Maternal Deaths',xlab='Time')

```
```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))#specify cran mirror
if (!require("lme4")) install.packages("lme4")#if required to install
library(lme4)#initiate from library
```

##check if model is overdisepersed'
```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))#specify cran mirror
if (!require("performance")) install.packages("performance")#if required to install
library(performance)
```


##OverDispersion is detected with Poisson model thus we must use negative binomial model

```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))#specify cran mirror
if (!require("glmmTMB")) install.packages("glmmTMB")#if required to install
library(glmmTMB)
```




```{r}
poissonmodel_glmm_ethnicity <- glmer(Maternal_Deaths ~ Ethnicity  + (1 | Month/Year), 
                              offset = log(Live_Births),
                              family = poisson(link = "log"), 
                              data = deaths_df)
poissonmodel_glmm_ethnicity
```

```{r}

jack<-deaths_df2%>%filter(Group != "Total" & Subgroup != "Total")
```

```{r}
poissonmodel_glmm_both <- glmer(Maternal_Deaths ~ Subgroup+ (1|Month/Year),
                              offset=log(Live_Births),
                              family = poisson(link = "log"), 
                              data = jack)
poissonmodel_glmm_both
```





```{r}
poissonmodel_glmm_ethnicity_nooffset <- glmer(Maternal_Deaths ~ Ethnicity + (1 |Month/ Year), 
                              family = poisson(link = "log"), 
                              data = deaths_df)
poissonmodel_glmm_ethnicity_nooffset

```

```{r}
poissonmodel_glmm_both_nooffset <- glmer(Maternal_Deaths ~ Subgroup + (1|Month/Year),#includes ethncity and age
                              family = poisson(link = "log"), 
                              data = jack)
poissonmodel_glmm_both_nooffset
```


```{r}
check_overdispersion(poissonmodel_glmm_ethnicity)
check_overdispersion(poissonmodel_glmm_ethnicity_nooffset)
check_overdispersion(poissonmodel_glmm_both)
check_overdispersion(poissonmodel_glmm_both_nooffset)
```
##overdispersion still detected

```{r}

##with offset
ethnicityonly_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Ethnicity + (1 |Month/Year),
  offset=log(Live_Births),
  family = nbinom2,
  data = deaths_df
)
summary(ethnicityonly_glmmodel_nb)
```

```{r}
both_glmmodel_nb <- glmmTMB(
  Maternal_Deaths ~  Subgroup+  (1 |Month/Year),
  offset=log(Live_Births),
  family = nbinom2,
  data = jack
)
summary(both_glmmodel_nb)
```

```{r}

###Without offset, Ethnicity as fixed effect, Year as random effect #no offset
ethnicityonly_glmmodel_nb2 <- glmmTMB(
  Maternal_Deaths ~  Ethnicity + (1 |Month/Year),
  family = nbinom2,
  data = deaths_df
)
summary(ethnicityonly_glmmodel_nb2)
```

```{r}
#without offset
both_glmmodel_nb2 <- glmmTMB(
  Maternal_Deaths ~  Subgroup + (1 |Month/Year),
  family = nbinom2,
  data = jack
)
summary(both_glmmodel_nb2)
```
```{r}
glmmodel_nb3 <- glmmTMB(
  Maternal_Deaths ~  Ethnicity +(1|Month/Year),
  family = nbinom2,
  data = deaths_df
)
summary(glmmodel_nb3)
```


```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cloud.r-project.org"))
if (!require("performance"))install.packages("performance")#if required to install
library(performance)

if (!require("DHARMa"))install.packages("DHARMa")#if required to install
library(DHARMa)

if (!require("sjPlot"))install.packages("sjPlot")#if required to install
library(sjPlot, quietly = FALSE, warn.conflicts = FALSE)
```

```{r}
performance::check_model(ethnicityonly_glmmodel_nb)
performance::check_model(both_glmmodel_nb)
performance::check_model(ethnicityonly_glmmodel_nb2)
performance::check_model(both_glmmodel_nb2)
```

```{r}
#for non-normal error models
sim <- simulateResiduals(ethnicityonly_glmmodel_nb)
plot(sim)
sim2 <- simulateResiduals(ethnicityonly_glmmodel_nb2)
plot(sim2)
sim3 <- simulateResiduals(both_glmmodel_nb)
plot(sim3)
sim4 <- simulateResiduals(both_glmmodel_nb2)
plot(sim4)
```

```{r}
sjPlot::tab_model(ethnicityonly_glmmodel_nb)

```

```{r}
sjPlot::tab_model(ethnicityonly_glmmodel_nb2)#no offset
```

```{r}
sjPlot::tab_model(both_glmmodel_nb)
```

```{r}
sjPlot::tab_model(both_glmmodel_nb2)#no offset
```

```{r}
sjPlot::tab_model(glmmodel_nb3)#no offset
```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
